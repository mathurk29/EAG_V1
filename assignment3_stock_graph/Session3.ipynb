{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting google-genai\n",
      "  Downloading google_genai-1.13.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in ./.venv/lib/python3.12/site-packages (from google-genai) (2.39.0)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-genai) (2.11.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in ./.venv/lib/python3.12/site-packages (from google-genai) (2.31.0)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in ./.venv/lib/python3.12/site-packages (from google-genai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "Downloading google_genai-1.13.0-py3-none-any.whl (164 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Installing collected packages: websockets, httpcore, anyio, httpx, google-genai\n",
      "\u001b[2K  Attempting uninstall: anyiom\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [httpcore]\n",
      "\u001b[2K    Found existing installation: anyio 3.7.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [httpcore]\n",
      "\u001b[2K    Uninstalling anyio-3.7.1:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [anyio]\n",
      "\u001b[2K      Successfully uninstalled anyio-3.7.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [anyio]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [google-genai][0m [google-genai]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi 0.104.1 requires anyio<4.0.0,>=3.7.1, but you have anyio 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anyio-4.9.0 google-genai-1.13.0 httpcore-1.0.9 httpx-0.28.1 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let $F_n$ be the $n$-th Fibonacci number, where $F_1 = 1, F_2 = 1, F_3 = 2, F_4 = 3, F_5 = 5, \\dots$\n",
      "The first three Fibonacci numbers are $F_1 = 1$, $F_2 = 1$, and $F_3 = 2$.\n",
      "\n",
      "We need to calculate the sum of exponentials of these first three Fibonacci numbers.\n",
      "Let $S = e^{F_1} + e^{F_2} + e^{F_3}$.\n",
      "We have $F_1 = 1, F_2 = 1, F_3 = 2$.\n",
      "So $S = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2$.\n",
      "\n",
      "Now we can approximate the value:\n",
      "$e \\approx 2.718281828$\n",
      "$e^2 \\approx (2.718281828)^2 \\approx 7.389056099$\n",
      "$2e \\approx 2(2.718281828) \\approx 5.436563656$\n",
      "$S = 2e + e^2 \\approx 5.436563656 + 7.389056099 \\approx 12.825619755$\n",
      "\n",
      "Thus, the sum is $e^1 + e^1 + e^2 = 2e + e^2$.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{2e+e^2}$\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Calculate the sum of exponentials of first 3 Fibonacci numbers\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 3 Fibonacci numbers are $F_1=1$, $F_2=1$, and $F_3=2$.\n",
    "We want to calculate the sum of exponentials of these first 3 Fibonacci numbers.\n",
    "Let the sum be $S = e^{F_1} + e^{F_2} + e^{F_3}$.\n",
    "We have $F_1=1$, $F_2=1$, and $F_3=2$.\n",
    "Then $S = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2$.\n",
    "We can approximate the value of $e$ as $2.71828$.\n",
    "So, $S = 2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.3890561984 \\approx 12.8256161984$.\n",
    "\n",
    "We are asked to calculate the sum of exponentials of the first 3 Fibonacci numbers.\n",
    "Let the first 3 Fibonacci numbers be $F_1$, $F_2$, and $F_3$.\n",
    "Then $F_1 = 1$, $F_2 = 1$, $F_3 = 2$.\n",
    "The sum of exponentials of these numbers is $e^{F_1} + e^{F_2} + e^{F_3} = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2 = e(2+e)$.\n",
    "If we use the approximation $e \\approx 2.71828$, then\n",
    "$2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.3890561984 \\approx 12.8256161984$.\n",
    "\n",
    "The exact value is $2e + e^2$.\n",
    "\n",
    "Final Answer: The final answer is $\\boxed{2e+e^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION_CALL: strings_to_chars_to_int|TSAI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def strings_to_chars_to_int(string):\n",
    "    return [ord(char) for char in string]\n",
    "\n",
    "def int_list_to_exponential_sum(int_list):\n",
    "    int_list = eval(int_list)\n",
    "    return sum(math.exp(i) for i in int_list)\n",
    "\n",
    "def fibonacci_numbers(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    fib_sequence = [0, 1]\n",
    "    for _ in range(2, n):\n",
    "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
    "    return fib_sequence[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FUNCTION_CALL: strings_to_chars_to_int|TSAI'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = response.text.strip()\n",
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FUNCTION_CALL', ' strings_to_chars_to_int|TSAI')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, function_info = response_text.split(\":\", 1)\n",
    "_, function_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('strings_to_chars_to_int', 'TSAI')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "\n",
    "func_name, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_caller(func_name, params):\n",
    "    \"\"\"Simple function caller that maps function names to actual functions\"\"\"\n",
    "    function_map = {\n",
    "        \"strings_to_chars_to_int\": strings_to_chars_to_int,\n",
    "        \"int_list_to_exponential_sum\": int_list_to_exponential_sum,\n",
    "        \"fibonacci_numbers\": fibonacci_numbers\n",
    "    }\n",
    "    \n",
    "    if func_name in function_map:\n",
    "        return function_map[func_name](params)\n",
    "    else:\n",
    "        return f\"Function {func_name} not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_result = function_caller(func_name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION_CALL: int_list_to_exponential_sum|[84, 83, 65, 73]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.137991617878097e+36"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = response.text.strip()\n",
    "_, function_info = response_text.split(\":\", 1)\n",
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "iteration_result = function_caller(func_name, params)\n",
    "iteration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL_ANSWER: 4.137991617878097e+36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called strings_to_chars_to_int with TSAI parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "iteration_2 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\\n\\n{iteration_2}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "LLM Response: FUNCTION_CALL: strings_to_chars_to_int|TSAI\n",
      "  Result: [84, 83, 65, 73]\n",
      "\n",
      "--- Iteration 2 ---\n",
      "LLM Response: FUNCTION_CALL: int_list_to_exponential_sum|[84, 83, 65, 73]\n",
      "  Result: 4.137991617878097e+36\n",
      "\n",
      "--- Iteration 3 ---\n",
      "LLM Response: FINAL_ANSWER: [4.137991617878097e+36]\n",
      "\n",
      "=== Agent Execution Complete ===\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 3\n",
    "last_response = None\n",
    "iteration = 0\n",
    "iteration_response = []\n",
    "\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "    if last_response == None:\n",
    "        current_query = query\n",
    "    else:\n",
    "        current_query = current_query + \"\\n\\n\" + \" \".join(iteration_response)\n",
    "        current_query = current_query + \"  What should I do next?\"\n",
    "\n",
    "    # Get model's response\n",
    "    prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    response_text = response.text.strip()\n",
    "    print(f\"LLM Response: {response_text}\")\n",
    "\n",
    "    \n",
    "    if response_text.startswith(\"FUNCTION_CALL:\"):\n",
    "        response_text = response.text.strip()\n",
    "        _, function_info = response_text.split(\":\", 1)\n",
    "        func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "        iteration_result = function_caller(func_name, params)\n",
    "\n",
    "    # Check if it's the final answer\n",
    "    elif response_text.startswith(\"FINAL_ANSWER:\"):\n",
    "        print(\"\\n=== Agent Execution Complete ===\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    print(f\"  Result: {iteration_result}\")\n",
    "    last_response = iteration_result\n",
    "    iteration_response.append(f\"In the {iteration + 1} iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}.\")\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
